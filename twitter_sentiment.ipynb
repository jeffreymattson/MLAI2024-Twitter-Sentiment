{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb76fa8c-e20b-43ca-88db-d72ab947122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d004c6-63f0-4d1e-9056-732b12c30659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f55758-7556-4dd1-8eef-d3b2743b00e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23ac3638-a821-4af5-a0a8-855cf9b50d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jmattson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jmattson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the tweet column\n",
    "df['cleaned_text'] = df['SentimentText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d68d6a5-5cb7-49d1-95b1-1ea98862866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>miss new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga im sooo im gunna cri ive dentist sinc s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>think mi bf cheat tt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText  \\\n",
       "0       1          0                       is so sad for my APL frie...   \n",
       "1       2          0                     I missed the New Moon trail...   \n",
       "2       3          1                            omg its already 7:30 :O   \n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4       5          0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                                     sad apl friend  \n",
       "1                              miss new moon trailer  \n",
       "2                                        omg alreadi  \n",
       "3  omgaga im sooo im gunna cri ive dentist sinc s...  \n",
       "4                               think mi bf cheat tt  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab22845c-a131-4400-a61d-48b56affe8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99989, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Display the shape of the feature matrix\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76cabe86-141f-4716-a6cd-33143bbd4af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1700)\t0.7232827010348476\n",
      "  (0, 3709)\t0.6905520504521983\n",
      "  (1, 4486)\t0.5991199483661498\n",
      "  (1, 2816)\t0.5732922558760698\n",
      "  (1, 2915)\t0.36067946812754204\n",
      "  (1, 2780)\t0.42696791225278546\n",
      "  (2, 135)\t0.6922262518507328\n",
      "  (2, 3037)\t0.7216805500002658\n",
      "  (3, 2768)\t0.30888050632533515\n",
      "  (3, 3417)\t0.2621695137500573\n",
      "  (3, 1030)\t0.4222846429977529\n",
      "  (3, 1778)\t0.1665514121950295\n",
      "  (3, 3914)\t0.26239551106556597\n",
      "  (3, 1151)\t0.3767515016072556\n",
      "  (3, 2284)\t0.21881271819685766\n",
      "  (3, 1036)\t0.2764076135148109\n",
      "  (3, 1907)\t0.36105584063838325\n",
      "  (3, 4020)\t0.29479133346442504\n",
      "  (3, 2182)\t0.2783159414536099\n",
      "  (4, 4526)\t0.4834703627443245\n",
      "  (4, 761)\t0.5241741686564342\n",
      "  (4, 439)\t0.4568026808859681\n",
      "  (4, 2747)\t0.47074441215050944\n",
      "  (4, 4378)\t0.24744465729869974\n",
      "  (5, 2845)\t0.5812207265603395\n",
      "  :\t:\n",
      "  (99983, 3530)\t0.2457139360888111\n",
      "  (99983, 1778)\t0.20797604860230548\n",
      "  (99984, 10)\t0.41315970113428263\n",
      "  (99984, 3792)\t0.4159078929477707\n",
      "  (99984, 3362)\t0.40453797019756643\n",
      "  (99984, 2093)\t0.29101622277702094\n",
      "  (99984, 1601)\t0.3570484695612653\n",
      "  (99984, 2519)\t0.24658177266006173\n",
      "  (99984, 4007)\t0.3538366805112433\n",
      "  (99984, 4976)\t0.30739501946513104\n",
      "  (99985, 3599)\t0.5099395048620226\n",
      "  (99985, 1196)\t0.45795813129588636\n",
      "  (99985, 2017)\t0.41767479623196724\n",
      "  (99985, 2179)\t0.2970951407168011\n",
      "  (99985, 4420)\t0.27493860959132355\n",
      "  (99985, 4548)\t0.33880316136818767\n",
      "  (99985, 3787)\t0.2777399361255334\n",
      "  (99986, 4933)\t0.7128700221862875\n",
      "  (99986, 4389)\t0.7012961795619038\n",
      "  (99987, 4958)\t0.7723931116913411\n",
      "  (99987, 1802)\t0.43421010329796433\n",
      "  (99987, 1723)\t0.3905066314602776\n",
      "  (99987, 2182)\t0.24974995093349978\n",
      "  (99988, 4958)\t0.7394710714056442\n",
      "  (99988, 1922)\t0.6731883351293222\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76d72f2e-e1db-4485-8f40-2cc42c78bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7510\n",
      "Precision: 0.7507\n",
      "Recall: 0.7510\n",
      "F1-Score: 0.7483\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70      8750\n",
      "           1       0.75      0.83      0.79     11248\n",
      "\n",
      "    accuracy                           0.75     19998\n",
      "   macro avg       0.75      0.74      0.74     19998\n",
      "weighted avg       0.75      0.75      0.75     19998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6d13efe-6d60-4392-a220-48586d9cda2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67      8750\n",
      "           1       0.73      0.84      0.79     11248\n",
      "\n",
      "    accuracy                           0.74     19998\n",
      "   macro avg       0.74      0.73      0.73     19998\n",
      "weighted avg       0.74      0.74      0.74     19998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "923363be-c990-43a6-aa7f-d60420840e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.64      0.70      8750\n",
      "           1       0.75      0.84      0.79     11248\n",
      "\n",
      "    accuracy                           0.75     19998\n",
      "   macro avg       0.75      0.74      0.74     19998\n",
      "weighted avg       0.75      0.75      0.75     19998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM classifier\n",
    "svm_clf = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b10547f-4934-4786-9b7a-2e9321279903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7350\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69      8750\n",
      "           1       0.75      0.79      0.77     11248\n",
      "\n",
      "    accuracy                           0.74     19998\n",
      "   macro avg       0.73      0.73      0.73     19998\n",
      "weighted avg       0.73      0.74      0.73     19998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the classifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "354f5ba0-92fb-498d-a415-eedacd0d8fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "# Example of a new text field\n",
    "new_text = \"I love this new product.\"\n",
    "\n",
    "# Preprocess the new text\n",
    "cleaned_new_text = preprocess_text(new_text)\n",
    "\n",
    "# Vectorize the new text\n",
    "new_text_vectorized = tfidf.transform([cleaned_new_text])\n",
    "\n",
    "# Predict the sentiment\n",
    "predicted_sentiment = clf.predict(new_text_vectorized)\n",
    "\n",
    "# Print the predicted sentiment\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ef37d-632c-45cb-bdc6-95fac01ca1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022a2e0-e3b6-43ef-9366-6c69537443b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74b1c4-563e-4e8f-9ad4-e723d27a3410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
